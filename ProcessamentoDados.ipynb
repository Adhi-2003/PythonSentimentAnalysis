{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from string import punctuation\n",
    "import pickle\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from nltk import tokenize\n",
    "from nltk import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _remove_url(dados):\n",
    "    dados_processados = list()\n",
    "    pattern1 = re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    pattern2 = re.compile('www?.(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "\n",
    "    for texto in dados:\n",
    "        texto_processado = re.sub(pattern1, \"\", texto)\n",
    "        texto_processado = re.sub(pattern2, \"\", texto_processado)\n",
    "        dados_processados.append(texto_processado)\n",
    "   \n",
    "    return dados_processados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _remove_hashtag(dados):\n",
    "    dados_processados = list()\n",
    "    pattern = re.compile('#[\\w]*')\n",
    "\n",
    "    for texto in dados:\n",
    "        texto_processado = re.sub(pattern, \"\", texto)\n",
    "        dados_processados.append(texto_processado)\n",
    "   \n",
    "    return dados_processados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _remove_mencao(dados):\n",
    "    dados_processados = list()\n",
    "    pattern = re.compile('@[\\w]*')\n",
    "\n",
    "    for texto in dados:\n",
    "        texto_processado = re.sub(pattern, \"\", texto)\n",
    "        dados_processados.append(texto_processado)\n",
    "   \n",
    "    return dados_processados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _lower(dados):\n",
    "    frase_processada = list()\n",
    "    \n",
    "    for texto in dados:\n",
    "        frase_processada.append(texto.lower())\n",
    "        \n",
    "    return frase_processada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _tokenize(dados):\n",
    "    tokens = []   \n",
    "    token_tweet = TweetTokenizer()\n",
    "    \n",
    "    for texto in dados:\n",
    "        tokens.append(token_tweet.tokenize(texto))\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _destokeniza(listas_tokens):\n",
    "    lista_frases = []\n",
    "    \n",
    "    for tokens in listas_tokens:\n",
    "        nova_frase = []\n",
    "        \n",
    "        for palavra in tokens:\n",
    "            nova_frase.append(palavra)\n",
    "        lista_frases.append(' '.join(nova_frase))\n",
    "        \n",
    "    return lista_frases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _padroniza_tokens(lista_tokens, dict_abreviacao):\n",
    "    lista_tokens_padronizados = list()\n",
    "    \n",
    "    for tokens in lista_tokens:\n",
    "        tokens_padronizados = list()\n",
    "        \n",
    "        for palavra in tokens:\n",
    "            if(palavra.lower() in dict_abreviacao):\n",
    "                tokens_padronizados.append(dict_abreviacao[palavra.lower()])\n",
    "            else :\n",
    "                tokens_padronizados.append(palavra)\n",
    "                \n",
    "        lista_tokens_padronizados.append(tokens_padronizados)\n",
    "        \n",
    "    return lista_tokens_padronizados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dicion√°rio\n",
    "<br/>\n",
    "Criado com a exp√™ncia do autor do projeto e tamb√©m baseado no artigo <a href=\"https://www.dicionariopopular.com/girias-abreviacoes-siglas-mais-usadas-do-whatsapp/\">G√≠rias e abrevia√ß√µes mais usadas do Whatsapp</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_abreviacoes = {\n",
    "    'eh': '√©', 'vc': 'voc√™', 'vcs': 'voc√™s','tb': 'tamb√©m', 'tbm': 'tamb√©m', 'obg': 'obrigado', 'gnt': 'gente', \n",
    "    'q': 'que', 'n': 'n√£o', 'cmg': 'comigo', 'p': 'para', 'ta': 'est√°', 'to': 'estou', 'vdd': 'verdade', \n",
    "    'rs': 'risos', 'sfd' : 'safado', 'slc' : 'voc√™ √© louco', 'slk' : 'voc√™ √© louco', 'rd' : 'rodado' , \n",
    "    'smdb': 'vai dar bom', 'smdd' : 'sem maldade', 'tqr' : 'tem que respeitar', 'pprt' : 'papo reto', \n",
    "    'bpn' : 'bom para n√≥s', 'pdp' : 'claro', 'tlg' : 'est√° ligado', 'dmr' : 'demorou', 'tmj' : ' estamos juntos', \n",
    "    'pdc' : 'pode cr√©', 'sqn' : 's√≥ que n√£o', 'tamo' : 'estamos', 'naum' : 'n√£o', '√±' : 'n√£o', 'lol' : 'risos', \n",
    "    't√£o' : 'est√£o', 'msm' : 'mesmo', 'pra' : 'para', 'ngm' : 'ningu√©m', 'bjo' : 'beijo', 'bjs' : 'beijos', \n",
    "    'smp' : 'sempre', 'agr' : 'agora', 'amg' : 'amigo', 'bb' : 'beb√™', 'blz' : 'beleza', 'sdds' : 'saudades'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_file = open(\"listas_dicionarios\\\\abreviacoes.pkl\", \"wb\")\n",
    "pickle.dump(lista_abreviacoes, a_file)\n",
    "a_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _replace_emoticons(tokens_list, emoticon_list):\n",
    "    new_tokens_list = []\n",
    "\n",
    "    for tokens in tokens_list:\n",
    "        new_tokens = []\n",
    "        \n",
    "        for palavra in tokens:\n",
    "            if(palavra in emoticon_list['emoticon_positivo']):\n",
    "                palavra = 'emoticon_positivo'\n",
    "            elif(palavra in emoticon_list['emoticon_negativo']):\n",
    "                palavra = 'emoticon_negativo'\n",
    "            elif(palavra in emoticon_list['emoticon_neutro']):\n",
    "                palavra = 'emoticon_neutro'\n",
    "                \n",
    "            new_tokens.append(palavra)\n",
    "            \n",
    "        new_tokens_list.append(new_tokens)\n",
    "\n",
    "    return new_tokens_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dicion√°rio de emoticons\n",
    "<br/>\n",
    "O dicin√°rio de emoticon √© composto por tr√™s strings que s√£o as chaves e tr√™s listas que s√£o os valores. As chaves s√£o: \"emoticon_positivo\", \"emoticon_negativo\" e \"emoticon_neutro\" que representam respectivamente emoticons positivos, negativos e neutros. As listas que s√£o mapeadas pelas chaves, s√£o listas com os mesmos nomes das chaves, possuem os pr√≥prios emoticons que foram inserido de acordo com sua polaridade (positivo, negativo ou neutro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi criado primeiro as listas de emoticons, essas listas foram criadas com base no trabalho <a href=\"https://s3.amazonaws.com/academia.edu.documents/46714369/Measuring_sentiments_in_online_social_ne20160622-29552-1huraui.pdf?response-content-disposition=inline%3B%20filename%3DMeasuring_sentiments_in_online_social_ne.pdf&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWOWYYGZ2Y53UL3A%2F20200212%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200212T200826Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=360d36561b04002a796f8f79c7f432b53235d2683f1757e91e4252fffed1ecde\">M√©todos para An√°lise de Sentimentos no Twitter</a> no qual apresenta t√©cnicas para an√°lise de sentiments e uma delas √© o uso de emoticons. A tabela de emoticon presente no trabalho foi toda utilizada, al√©m de de incluir novos emoticons com base a experi√™ncia do autor desse projeto. Tamb√©m foi necess√°rio incluir equivalentes em min√∫sculo de todos os emoticons que possuem caracters em mai√∫sculo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticon_positivo = [':))', ':)', ':D',':d', 'ü§£', ':]', ':}', ':o)', ':o]', ':o}', ':-]', ':-)', ':-}', '=)', '=]', '=}', '=^]',\n",
    "                     '=^)', '=^}', ':B',':b', ':-D',':-d', ':-B',':-b', ':^D',':^d', ':^B',':^b', ':^D',':^d', ':^B',':^b', '=B',\n",
    "                     '=b', '=^B','=^b', '=^D', '=^d', ':‚Äô)', ':‚Äô]', ':‚Äô}', '=‚Äô)', '=‚Äô]', '=‚Äô}', '<3', '^.^', '^-^', '^_^', '^^', \n",
    "                     ':*', '=*', ':-*', ';)', ';]', ';}', ':-p', ':-P', ':-b', ':^p', ':^P', ':^b', '=P', '=p', ':P', ':p',\n",
    "                     ':b', '=b', '=^p', '=^P', '=^b', '\\o/' ]\n",
    "emoticon_negativo = [':(', ':((', 'ü§Æ', 'D:', 'd:','D=','d=', 'D-:', 'd-:', 'D^:','d^:' , 'D^=', 'd^=', ':(', ':[', ':{', \n",
    "                     ':o(', ':o[', ':^(', ':^[', ':^{', '=^(', '=^{', '>=(', '>=[', '>={', '>=(', '>:-{', '>:-[', '>:-(', \n",
    "                     '>=^[', '>:-(', ':-[', ':-(', '=(', '=[', '={', '=^[', '>:-=(', '>=[', ':‚Äô(', ':‚Äô[', ':‚Äô{', '=‚Äô{', \n",
    "                     '=‚Äô(', '=‚Äô[', '=/', ':/', '=$', 'o.O','o.o', 'O_o', 'o_o', 'Oo', 'oo', ':$:-{', '>:-{', '>=^(', \n",
    "                     '>=^{', ':o{']\n",
    "emoticon_neutro = ['8)', ':|', '=|', ':-|', '>.<', '><', '>_<', ':o', ':0', '=O', ':@', '=@', ':^o', ':^@', '-.-', '-.-‚Äô', \n",
    "                    '-_-', '-_-‚Äô', ':x', '=X', '=#', ':-x', ':-@', ':-#', ':^x', ':^#', ':#']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tamb√©m foi utilizado outro trabalho para compor o dicion√°rio, <a href=\"https://www.clarin.si/repository/xmlui/handle/11356/1048\">Emoji Sentiment Ranking 1.0\n",
    "</a>, em que um grupo de pessoas classificaram manualmente v√°rios tweets como positivos, negativos e neutros. Com isso foi criado um ranking com os emoticons desses tweets de acordo com a frequ√™ncia daquele emoticon. Da quantidade de tweets que aquele emoticon aparecia, est√° presente tamb√©m quantos foram positivos, negativos ou neutros. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emoji</th>\n",
       "      <th>Unicode codepoint</th>\n",
       "      <th>Occurrences</th>\n",
       "      <th>Position</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Unicode name</th>\n",
       "      <th>Unicode block</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>üòÇ</td>\n",
       "      <td>0x1f602</td>\n",
       "      <td>14622</td>\n",
       "      <td>0.805101</td>\n",
       "      <td>3614</td>\n",
       "      <td>4163</td>\n",
       "      <td>6845</td>\n",
       "      <td>FACE WITH TEARS OF JOY</td>\n",
       "      <td>Emoticons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>‚ù§</td>\n",
       "      <td>0x2764</td>\n",
       "      <td>8050</td>\n",
       "      <td>0.746943</td>\n",
       "      <td>355</td>\n",
       "      <td>1334</td>\n",
       "      <td>6361</td>\n",
       "      <td>HEAVY BLACK HEART</td>\n",
       "      <td>Dingbats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>‚ô•</td>\n",
       "      <td>0x2665</td>\n",
       "      <td>7144</td>\n",
       "      <td>0.753806</td>\n",
       "      <td>252</td>\n",
       "      <td>1942</td>\n",
       "      <td>4950</td>\n",
       "      <td>BLACK HEART SUIT</td>\n",
       "      <td>Miscellaneous Symbols</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>üòç</td>\n",
       "      <td>0x1f60d</td>\n",
       "      <td>6359</td>\n",
       "      <td>0.765292</td>\n",
       "      <td>329</td>\n",
       "      <td>1390</td>\n",
       "      <td>4640</td>\n",
       "      <td>SMILING FACE WITH HEART-SHAPED EYES</td>\n",
       "      <td>Emoticons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>üò≠</td>\n",
       "      <td>0x1f62d</td>\n",
       "      <td>5526</td>\n",
       "      <td>0.803352</td>\n",
       "      <td>2412</td>\n",
       "      <td>1218</td>\n",
       "      <td>1896</td>\n",
       "      <td>LOUDLY CRYING FACE</td>\n",
       "      <td>Emoticons</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Emoji Unicode codepoint  Occurrences  Position  Negative  Neutral  Positive  \\\n",
       "0     üòÇ           0x1f602        14622  0.805101      3614     4163      6845   \n",
       "1     ‚ù§            0x2764         8050  0.746943       355     1334      6361   \n",
       "2     ‚ô•            0x2665         7144  0.753806       252     1942      4950   \n",
       "3     üòç           0x1f60d         6359  0.765292       329     1390      4640   \n",
       "4     üò≠           0x1f62d         5526  0.803352      2412     1218      1896   \n",
       "\n",
       "                          Unicode name          Unicode block  \n",
       "0               FACE WITH TEARS OF JOY              Emoticons  \n",
       "1                    HEAVY BLACK HEART               Dingbats  \n",
       "2                     BLACK HEART SUIT  Miscellaneous Symbols  \n",
       "3  SMILING FACE WITH HEART-SHAPED EYES              Emoticons  \n",
       "4                   LOUDLY CRYING FACE              Emoticons  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emojis_ranking = pd.read_csv(\"listas_dicionarios\\\\Emoji_Sentiment_Data_v1.0.csv\")\n",
    "emojis_ranking.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lista em que cada emoticon foi inserido vai depender da sua frequ√™ncia dos tweets classificados, na classe de tweet que um certo emoticon mais aparecer, vai ser inserido na lista correspondente aquela classe. Ex. O primeiro emoticon do ranking esta mais presente nos tweets classificados como positivos, ent√£o vai ser inserido na lista \"emoticon_positivo\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0, len(emojis_ranking[\"Emoji\"])):\n",
    "    if(emojis_ranking[\"Negative\"][i] > emojis_ranking[\"Positive\"][i] and emojis_ranking[\"Negative\"][i] > emojis_ranking[\"Neutral\"][i]):\n",
    "        emoticon_negativo.append(emojis_ranking[\"Emoji\"][i])\n",
    "    elif (emojis_ranking[\"Positive\"][i] > emojis_ranking[\"Negative\"][i] and emojis_ranking[\"Positive\"][i] > emojis_ranking[\"Neutral\"][i]):\n",
    "        emoticon_positivo.append(emojis_ranking[\"Emoji\"][i])\n",
    "    else:\n",
    "        emoticon_neutro.append(emojis_ranking[\"Emoji\"][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim o dicion√°rio √© criado mapeando a chave com o a lista correpondente "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'emoticon_positivo': [':))', ':)', ':D', ':d', 'ü§£', ':]', ':}', ':o)', ':o]', ':o}', ':-]', ':-)', ':-}', '=)', '=]', '=}', '=^]', '=^)', '=^}', ':B', ':b', ':-D', ':-d', ':-B', ':-b', ':^D', ':^d', ':^B', ':^b', ':^D', ':^d', ':^B', ':^b', '=B', '=b', '=^B', '=^b', '=^D', '=^d', ':‚Äô)', ':‚Äô]', ':‚Äô}', '=‚Äô)', '=‚Äô]', '=‚Äô}', '<3', '^.^', '^-^', '^_^', '^^', ':*', '=*', ':-*', ';)', ';]', ';}', ':-p', ':-P', ':-b', ':^p', ':^P', ':^b', '=P', '=p', ':P', ':p', ':b', '=b', '=^p', '=^P', '=^b', '\\\\o/', 'üòÇ', '‚ù§', '‚ô•', 'üòç', 'üòò', 'üòä', 'üëå', 'üíï', 'üëè', 'üòÅ', '‚ò∫', '‚ô°', 'üëç', 'üôè', '‚úå', 'üòâ', 'üôå', 'üôà', 'üí™', 'üòÑ', 'üíÉ', 'üíñ', 'üòÉ', 'üò±', 'üéâ', 'üòú', 'üå∏', 'üíú', 'üíô', 'üò≥', 'üíó', '‚òÄ', 'üòé', 'üò¢', 'üíã', 'üòã', 'üôä', 'üé∂', 'üíû', 'üòå', 'üíØ', 'üíõ', 'üíÅ', 'üíö', 'üòÜ', 'üòù', 'üòÖ', 'üëä', 'üòÄ', 'üòö', 'üòª', 'üíò', 'üëã', '‚úã', 'üéä', 'üçï', '‚ùÑ', 'üò•', 'üòà', 'üîù', '‚öΩ', 'üëë', 'üòπ', 'üçÉ', 'üéÅ', 'üêß', 'üéà', '‚úä', 'üí§', 'üíì', 'üí¶', 'üôã', 'üéÑ', 'üéµ', 'üòõ', 'üò¨', 'üëØ', 'üíé', 'üéÇ', 'üë´', 'üèÜ', '‚òù', 'üòô', '‚õÑ', 'üëÖ', '‚ô™', 'üçÇ', 'üíè', 'üå¥', 'üëà', 'üåπ', 'üôÜ', 'üçª', 'üåû', 'üçÅ', '‚≠ê', 'üéÄ', 'üôâ', 'üå∫', 'üíÖ', 'üê∂', 'üåö', 'üé§', 'üë≠', 'üéß', 'üëÜ', 'üç∏', 'üçâ', 'üòá', 'üèÉ', 'üç∫', 'üé∏', 'üçπ', 'üí´', 'üìö', 'üå∑', 'üíù', 'üí®', 'üèà', 'üíç', '‚òî', 'üë∏', 'üá™', 'üç©', '‚òÅ', 'üåª', 'üòµ', '‚Üø', 'üêØ', 'üëº', 'üçî', 'üò∏', 'üë∂', '‚Üæ', 'üíê', 'üåä', 'üç¶', 'üçì', 'üíÜ', 'üç¥', 'üá∏', 'üòÆ', 'üòΩ', 'üåà', 'üôÄ', 'üéÆ', 'üçÜ', 'üç∞', 'üôá', 'üçü', 'üçå', 'üíë', 'üê£', 'üéÉ', 'üòü', 'üêæ', 'üéì', 'üèä', 'üç´', 'üì∑', 'üëÑ', 'üåº', 'üê±', 'üá∫', 'üö¨', 'üìñ', 'üêí', 'üåç', '‚îä', 'üê•', 'üíÑ', 'üí∏', '‚õî', 'üèÄ', 'üíâ', 'üíü', 'üòØ', '‚ô¶', 'üåô', 'üêü', 'üë£', 'üóø', 'üçù', 'üç≠', '‚ùå', 'üê∞', 'üíä', 'üö®', 'üç™', 'üéÜ', 'üéé', 'üá©', '‚úÖ', 'üçë', 'üîä', 'üåå', 'üçé', 'üêª', 'üíá', 'üçä', 'üçí', 'üê≠', 'üëü', 'üåé', 'üçç', 'üêÆ', 'üåÖ', 'üá∑', 'üë†', 'üåΩ', 'üç¨', 'üò∫', 'üöÄ', '¬¶', 'üçß', 'üçú', 'üêè', 'üëß', 'üèÑ', 'üÜó', 'üì∫', 'üçÖ', '‚õÖ', 'üëô', 'üè°', 'üåæ', 'üê¨', 'üáπ', '‚ô£', 'üáÆ', 'üêç', '‚ôî', 'üç≥', 'üîµ', 'üåï', 'üê®', 'üîê', 'üíø', 'üå≥', 'üë∞', '‚öì', 'üö¥', '‚ûï', 'üí¨', 'üîú', 'üç®', 'üçô', 'üçó', 'üòº', 'üêô', 'üë®', 'üçö', 'üçñ', '‚ô®', '‚ñÉ', 'üöò', 'üë©', 'üê†', 'üöπ', 'üíµ', '‚ú∞', 'üëõ', 'üå±', 'üåè', 'üå≤', 'üë¥', 'üè†', 'üçá', 'üçò', 'üçõ', 'üêá', 'üëµ', 'üåµ', 'üéá', 'üêé', 'üê§', 'üõÄ', 'üåë', 'üèÅ', 'üéæ', 'üêµ', 'üóº', 'üçµ', 'üçØ', '‚á®', 'üåì', 'üîí', 'üë≥', '‚ô©', 'üíå', 'üåú', 'üöø', 'üîÜ', 'üåõ', 'üè©', 'üá´', '‚ôª', 'üåò', 'üçê', 'üåî', '‚ï•', 'üòó', 'üêÑ', '‚¨á', 'üöº', 'üåó', 'üåñ', 'üîÖ', 'üêå', 'üíº', 'üêπ', 'üå†', '‚ö´', '‚ôß', 'üé¢', 'üé∑', 'üåá', '‚è∞', '‚ó†', 'üéø', 'üÜî', 'üåí', 'üê™', '‚ïù', 'üëî', '‚ñΩ', 'üêõ', 'üëï', 'üí≥', 'üèß', 'üí°', '‚¨Ö', 'üìπ', 'üëû', 'üÜò', 'üëö', 'üöç', 'üö£', 'üèâ', 'üóª', '‚õ∫', 'üèÇ', 'üë°', 'üìª', 'üå∞', 'üéí', '‚åí', 'üì¥', 'üö¢', 'üîî', '‚ó¢', 'üÉè', 'üíí', 'üêê', 'üîö', 'üîì', 'üéΩ', 'üìÖ', 'üé∫', '‚ó§', '‚óã', 'üçº', 'üì£', 'üêó', '‚õ≥', '‚îõ', 'üìû', 'üåâ', '‚úé', 'üìÉ', 'üí∑', 'üöÑ', '‚ñ≤', '‚õµ', '‚åõ', 'üöú', 'üîõ', 'üá≤', '‚ùÖ', 'üëù', 'üéã', 'üë•', '‚óÜ', 'üêú', '‚ôå', 'üë∑', 'üìÑ', 'üöê', 'üåã', 'üì°', 'üö≥', '‚úò', 'üÖ∞', '‚îì', '‚î£', 'üë§', 'üé†', 'üë¢', 'üì∞', '‚ìÇ', 'üöä', 'üî≤', 'üìÜ', 'üîé', 'üìò', '‚ìî', 'üîë', 'üö≠', 'üöâ', 'üö™', 'üöÉ', 'üÜñ', '‚îó', '‚ùá', '‚ú¥', '‚òä', 'üöû', 'üç∂', 'üåê', 'üöÖ', '‚ôç', '‚ìê', 'üìô', 'üìã', 'üé±', '‚ì°', '‚ô§', 'üéØ', 'üîâ', '‚Ü©', 'üéå', '‚è¨', '‚ìû', '‚òö', 'üìë', '‚ìß', 'üîü', '„Äì', '‚û†', 'üöΩ', '‚ìù', '‚á¶', 'üî¨', '‚óé', 'üìé', '‚ëÖ', '‚ú≠', '‚îè', '‚òá', 'üëò', '‚Üô', 'üïõ', '‚Ü¨', '‚úç', 'üè¶', 'üîª', '‚ìü', '‚ìï', '‚ìò', '‚ôø', '‚áó', '‚áò', '‚ì®', '‚ìô', '‚ñ´', 'üîá', 'üîñ', 'üìú', 'üöù', 'üîØ', '‚û∏', 'Ííµ', '‚úΩ', 'üìº', 'üÄÑ', '‚ú¨', '‚ú´', '‚ù£', 'üì´', 'üâê', 'üìî'], 'emoticon_negativo': [':(', ':((', 'ü§Æ', 'D:', 'd:', 'D=', 'd=', 'D-:', 'd-:', 'D^:', 'd^:', 'D^=', 'd^=', ':(', ':[', ':{', ':o(', ':o[', ':^(', ':^[', ':^{', '=^(', '=^{', '>=(', '>=[', '>={', '>=(', '>:-{', '>:-[', '>:-(', '>=^[', '>:-(', ':-[', ':-(', '=(', '=[', '={', '=^[', '>:-=(', '>=[', ':‚Äô(', ':‚Äô[', ':‚Äô{', '=‚Äô{', '=‚Äô(', '=‚Äô[', '=/', ':/', '=$', 'o.O', 'o.o', 'O_o', 'o_o', 'Oo', 'oo', ':$:-{', '>:-{', '>=^(', '>=^{', ':o{', 'üò≠', 'üò©', 'üòí', 'üòî', 'üò°', 'üò¥', 'üî´', 'üòû', 'üò™', 'üò´', 'üíÄ', 'üòï', 'üíî', 'üò§', 'üò∞', 'üòë', 'üò†', 'üòì', 'üò£', 'üòê', 'üò®', 'üòñ', 'üëé', 'üò∑', 'üí©', 'üôÖ', 'üòø', 'üò≤', 'üò∂', 'üòß', 'üö´', 'üëê', 'Ôøº', 'üëø', '‚úÇ', 'üë™', 'üò¶', 'üç£', 'üôç', 'üç±', 'üíß', 'üîã', 'üòæ', 'üç•', '‚öæ', 'üçÆ', 'üëÆ', '‚òπ', '‚î≥', 'üë∫', 'üíÇ', 'üôé', '‚îà', '‚ñ°', 'üè´', '‚ñ†', 'üçà', '‚û∞', '‚îª', 'üèá', 'üìå', '‚òê', 'üîß', 'üîï', '‚¨õ', 'üé£', '‚ùé', '‚ûñ', '‚ÑÖ', 'Íí¶', '‡øé', '‚ôà', '‚åÉ', '‚îò', '‚úù', '‚ç£', 'üìÆ', 'üïï', 'üï•', 'üïê', 'üïî', 'üàÇ', 'üé∞', '“Ç', '‚ï§'], 'emoticon_neutro': ['8)', ':|', '=|', ':-|', '>.<', '><', '>_<', ':o', ':0', '=O', ':@', '=@', ':^o', ':^@', '-.-', '-.-‚Äô', '-_-', '-_-‚Äô', ':x', '=X', '=#', ':-x', ':-@', ':-#', ':^x', ':^#', ':#', 'üòè', '‚òØ', '‚ú®', '‚òÖ', '‚ñà', 'üî•', '‚ô´', 'ÔøΩ', '¬©', 'üëÄ', 'üêì', '‚òï', 'üí•', '‚ñ∫', '‚úà', 'üëâ', '‚òÜ', 'üçÄ', 'üéÖ', '‚úî', '‚ö°', '‚û°', 'üåø', 'üåü', 'üîÆ', '‚ùó', '‚úñ', 'üî™', '‚ûú', 'üëª', 'üí∞', '‚ñ™', '‚îÅ', '‚ò∑', 'üê∑', 'üëΩ', 'üç∑', '¬Æ', '‚òë', '‚îÇ', 'üí£', '‚ñ∂', '‚ñë', 'üëæ', 'üìí', 'üëá', '‚ñì', '‚ö†', '‚ïØ', '‚úì', 'üë¨', '‚ñ¨', 'üö∂', '‚ïë', 'üê∏', '‚úø', 'üåÄ', 'üêº', 'üé•', '‚óè', 'üöó', 'üìù', '‚ïê', 'üí≠', '‚òû', 'üåÉ', '‚ï≠', '‚úß', '‚ïÆ', 'üëπ', 'üì±', 'üéº', '‚îÄ', '‚ï∞', '‚ô¨', '‚ôö', 'üî¥', 'üì≤', '‚òº', '‚ùì', 'üê¥', 'üí¢', 'üé¨', 'üêò', '‚†Ä', '‚û§', '‚¨Ü', 'üçã', '‚ö™', 'üê¢', '‚óâ', '‚úè', 'üç§', 'üêù', 'üåù', '‚ùÅ', '‚ùÄ', '‚ñÄ', 'üëó', '‚ñí', 'üí≤', '‚õΩ', 'üç≤', '‚ñ∏', '‚ôõ', 'üéπ', '‚ôï', 'üçè', 'üë¶', 'üá¨', 'üáß', '‚ò†', '‚ï†', 'üöô', 'üíª', '‚ñÑ', 'üëì', '‚óÑ', 'üîû', '‚óÄ', 'üîô', 'üêΩ', '‚ûî', 'üí∂', '‚ï©', 'üö≤', 'üêë', 'üçû', '‚ïö', 'üàπ', 'üê≥', '‚ú™', '‚óï', '‚ñê', '‚ô†', 'üêö', 'üëÇ', 'üóΩ', 'üÜí', 'üê∫', '‚û®', '‚ï¨', 'üåÇ', 'üöå', 'üç°', '‚ù•', 'üé°', 'üê©', '‚åö', 'üêñ', 'üêî', 'üî®', 'üì¢', 'üê¶', 'üê≤', '‚ùä', 'üëñ', 'üö∫', 'üé≠', '‚óü', 'üç¢', 'üé®', '‚õ≤', '‚ñÅ', 'üá¥', 'üëú', 'üöï', 'üêà', '‚áß', '‚òé', 'üåÅ', 'üè∞', 'üöµ', 'üéê', '‚ïó', '‚ï±', '‚á©', 'üöÇ', '‚ú¶', '‚õ™', '‚ïî', 'üî±', 'üÜì', 'üêã', '‚ñÇ', 'üöã', 'üåÜ', 'üîπ', 'üç†', 'üê´', 'üè™', '€©', 'üá±', 'üöë', 'üêÇ', '‚ú≥', 'üêÄ', '‚ï¶', 'üêï', '‚úí', 'üè¢', 'üöö', 'üêâ', '‚ùí', 'üêä', 'üè•', '‚ùî', 'üöñ', '‚ñº', '‚ñå', '‚òõ', '‚ú©', 'üö§', 'üéª', 'üî∑', 'üö¶', '‚úØ', '‚úâ', '‚ï£', 'üìÄ', 'üöõ', 'üìì', '‚òâ', 'üí¥', '‚îº', 'üêÉ', 'üîå', 'üçÑ', 'üìï', 'üöì', '‚Ü™', '‚îÉ', 'üë±', '‚è≥', 'üí∫', '‚òª', '‚í∂', 'üö©', 'üè®', '‚ôé', 'üî∏', 'üêÜ', 'üëí', '‚ùï', '‚ô¢', '‚úû', '‚ó°', 'üìµ', 'üê°', 'üèØ', '‚òÇ', 'üî≠', 'üé™', '‚Ü≥', 'üîà', 'üìç', 'üöî', '‚è©', '€û', '‚òæ', 'üì•', 'üáº', '‚ìÅ', '‚í∫', 'üî¶', 'üöÅ', 'üêÅ', 'üìó', '‚îê', '‚òÆ', '‚ôÇ', '‚óû', 'üìØ', 'üî©', '‚óÇ', 'üì∂', 'üö•', 'üåÑ', 'üóæ', 'üî∂', 'üè§', 'üé©', 'üêÖ', '‚ôÆ', 'üÖæ', 'üîÑ', '‚òÑ', '‚ò®', 'üì¶', 'üîÅ', '‚ñ≥', '‚ùõ', 'üìâ', '‚ñµ', '‚òú', 'üáØ', 'üáµ', '‚ú°', 'üîÉ', 'üëÉ', '‚≠ï', 'üîò', '‚ìí', '‚û≥', '‚îØ', 'üè¨', '‚òΩ', 'üÜô', '‚ò™', 'üöÆ', '‚î´', '‚ìÑ', '‚îå', '‚ùù', '‚ùû', '‚ôÄ', 'üöí', '‚û£', '‚ôã', 'üïù', '‚úó', '‚ìà', '‚á¢', 'üêû', 'üî∫', 'üéç', 'üé≤', '„Ä†', 'üöæ', 'üî£', '‚û•', 'üÖ±', '‚ó£', '‚ô≠', 'üí†', 'üî≥', 'üè≠', 'üî∞', 'üé≥', '‚ûΩ', '‚û´', 'üèÆ', 'üìõ', 'Íí∞', 'Íí±', '‚óù', 'üé¶', 'üá®', 'üá≥', '‚ìú', 'üöÜ', 'üö†', '‚òÉ', 'üìê', '‚úÆ', 'üë≤', 'üö°', 'üéë', '‚ûó', 'üìà', '‚åò', '‚è™', '‚ïπ', 'üîº', '‚çù', 'üìÅ', '‚û≤', '‚ôì', '‚ô∫', '‚ôû', 'üì†', '‚íª', '‚ìå', '‚ìÖ', 'üïë', 'üíΩ', 'üé´', 'üìü', '‚ÑÉ', 'üïí', 'üá∞', '‚Ü±', '‚áê', '‚ôè', '‚ò¢', 'üéè', '‚ùñ', 'üá≠', '‚óú', '‚ôô', '‚ñø', '‚öÉ', '‚úæ', 'üÜë', '‚û±', 'üÜï', '‚û¢', '‚Üï', '‚ôä', '‚ûõ', '‚ôù', '‚ùã', '‚úÜ']}\n"
     ]
    }
   ],
   "source": [
    "emoticon_list = { 'emoticon_positivo' : emoticon_positivo , 'emoticon_negativo' : emoticon_negativo , 'emoticon_neutro' : emoticon_neutro}\n",
    "print(emoticon_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_file = open(\"listas_dicionarios\\\\emoticon_list.pkl\", \"wb\")\n",
    "pickle.dump(emoticon_list, a_file)\n",
    "a_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _remove_stopwords(tokens_list, stopwords_list):\n",
    "    new_tokens_list = list()\n",
    "    \n",
    "    for tokens in tokens_list:\n",
    "        new_tokens = list()\n",
    "        \n",
    "        for palavra in tokens:\n",
    "            if palavra not in stopwords_list:\n",
    "                new_tokens.append(palavra)\n",
    "                \n",
    "        new_tokens_list.append(new_tokens)\n",
    "    return new_tokens_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = nltk.corpus.stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pontuacao = list()\n",
    "for ponto in punctuation:\n",
    "    pontuacao.append(ponto)\n",
    "    \n",
    "stopwords_customizadas = stopwords_list + pontuacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_customizadas.append(\"reforma\")\n",
    "stopwords_customizadas.append(\"previdencia\")\n",
    "stopwords_customizadas.append(\"previd√™ncia\")\n",
    "stopwords_customizadas.append(\"...\")\n",
    "stopwords_customizadas.append(\"....\")\n",
    "stopwords_customizadas.append(\"vou\")\n",
    "stopwords_customizadas.append(\"que\")\n",
    "stopwords_customizadas.append(\"¬´\")\n",
    "stopwords_customizadas.append(\"¬ª\")\n",
    "stopwords_customizadas.append(\"¬ª\")\n",
    "stopwords_customizadas.append(\"rt\")\n",
    "stopwords_customizadas.append(\"‚Ä¶\")\n",
    "stopwords_customizadas.append(\"http\")\n",
    "stopwords_customizadas.append(\"htt\")\n",
    "stopwords_customizadas.append(\"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['de', 'a', 'o', 'que', 'e', '√©', 'do', 'da', 'em', 'um', 'para', 'com', 'n√£o', 'uma', 'os', 'no', 'se', 'na', 'por', 'mais', 'as', 'dos', 'como', 'mas', 'ao', 'ele', 'das', '√†', 'seu', 'sua', 'ou', 'quando', 'muito', 'nos', 'j√°', 'eu', 'tamb√©m', 's√≥', 'pelo', 'pela', 'at√©', 'isso', 'ela', 'entre', 'depois', 'sem', 'mesmo', 'aos', 'seus', 'quem', 'nas', 'me', 'esse', 'eles', 'voc√™', 'essa', 'num', 'nem', 'suas', 'meu', '√†s', 'minha', 'numa', 'pelos', 'elas', 'qual', 'n√≥s', 'lhe', 'deles', 'essas', 'esses', 'pelas', 'este', 'dele', 'tu', 'te', 'voc√™s', 'vos', 'lhes', 'meus', 'minhas', 'teu', 'tua', 'teus', 'tuas', 'nosso', 'nossa', 'nossos', 'nossas', 'dela', 'delas', 'esta', 'estes', 'estas', 'aquele', 'aquela', 'aqueles', 'aquelas', 'isto', 'aquilo', 'estou', 'est√°', 'estamos', 'est√£o', 'estive', 'esteve', 'estivemos', 'estiveram', 'estava', 'est√°vamos', 'estavam', 'estivera', 'estiv√©ramos', 'esteja', 'estejamos', 'estejam', 'estivesse', 'estiv√©ssemos', 'estivessem', 'estiver', 'estivermos', 'estiverem', 'hei', 'h√°', 'havemos', 'h√£o', 'houve', 'houvemos', 'houveram', 'houvera', 'houv√©ramos', 'haja', 'hajamos', 'hajam', 'houvesse', 'houv√©ssemos', 'houvessem', 'houver', 'houvermos', 'houverem', 'houverei', 'houver√°', 'houveremos', 'houver√£o', 'houveria', 'houver√≠amos', 'houveriam', 'sou', 'somos', 's√£o', 'era', '√©ramos', 'eram', 'fui', 'foi', 'fomos', 'foram', 'fora', 'f√¥ramos', 'seja', 'sejamos', 'sejam', 'fosse', 'f√¥ssemos', 'fossem', 'for', 'formos', 'forem', 'serei', 'ser√°', 'seremos', 'ser√£o', 'seria', 'ser√≠amos', 'seriam', 'tenho', 'tem', 'temos', 't√©m', 'tinha', 't√≠nhamos', 'tinham', 'tive', 'teve', 'tivemos', 'tiveram', 'tivera', 'tiv√©ramos', 'tenha', 'tenhamos', 'tenham', 'tivesse', 'tiv√©ssemos', 'tivessem', 'tiver', 'tivermos', 'tiverem', 'terei', 'ter√°', 'teremos', 'ter√£o', 'teria', 'ter√≠amos', 'teriam', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~', 'reforma', 'previdencia', 'previd√™ncia', '...', '....', 'vou', 'que', '¬´', '¬ª', '¬ª', 'rt', '‚Ä¶', 'http', 'htt', \"'\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords_customizadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_file = open(\"listas_dicionarios\\\\stopwords_customizadas.pkl\", \"wb\")\n",
    "pickle.dump(stopwords_customizadas, a_file)\n",
    "a_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import seaborn as sns\n",
    "\n",
    "def _nuvem_de_palavras(lista_texto):\n",
    "    \n",
    "    todas_palavras = ' '.join([texto for texto in lista_texto])\n",
    "    nuvem_palavras = WordCloud(width=1600, height=1000, max_font_size=200, collocations=False, background_color=\"white\").generate(todas_palavras)\n",
    "    \n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.imshow(nuvem_palavras, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _processamento(textos):\n",
    "   \n",
    "    textos_processados = _lower(textos)\n",
    "    textos_processados = _remove_url(textos_processados)\n",
    "    textos_processados = _remove_hashtag(textos_processados)\n",
    "    textos_processados = _remove_mencao(textos_processados)\n",
    "    \n",
    "    tokens = _tokenize(textos_processados)\n",
    "    tokens = _padroniza_tokens(tokens, lista_abreviacoes)\n",
    "    tokens = _replace_emoticons(tokens, emoticon_list) \n",
    "    tokens = _remove_stopwords(tokens, stopwords_customizadas)\n",
    "    \n",
    "    textos_processados = _destokeniza(tokens)\n",
    "    \n",
    "    return textos_processados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_classificada = pd.read_csv(\"dados\\\\tweets_treino.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Classificacao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Trio √© detido ap√≥s assaltar pizzaria em Uberl√¢...</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>@PMMG190 - 42¬∫ BPM: POLICIAIS MILITARES DE CUR...</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Pres√≠dio em Minas adota novo modelo e consegue...</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Um jovem √© preso, um menor apreendido por tr√°f...</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Trio √© preso suspeito de roubo, tr√°fico e abus...</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14694</td>\n",
       "      <td>https://t.co/KJUowqIpT2 \"Procedimentos s√£o mui...</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14695</td>\n",
       "      <td>#Noticia #MPU: Est√° confirmado que o #edital s...</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14696</td>\n",
       "      <td>Programa√ß√£o SIPAT 2018 https://t.co/tJEy1KERUx...</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14697</td>\n",
       "      <td>#TheVoiceBrasil Esses jurados viram mais pela ...</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14698</td>\n",
       "      <td>A onda da transforma√ß√£o s√≥ cresce. Dia 7 de ou...</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14699 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text Classificacao\n",
       "0      Trio √© detido ap√≥s assaltar pizzaria em Uberl√¢...      Positivo\n",
       "1      @PMMG190 - 42¬∫ BPM: POLICIAIS MILITARES DE CUR...      Positivo\n",
       "2      Pres√≠dio em Minas adota novo modelo e consegue...      Positivo\n",
       "3      Um jovem √© preso, um menor apreendido por tr√°f...      Positivo\n",
       "4      Trio √© preso suspeito de roubo, tr√°fico e abus...      Positivo\n",
       "...                                                  ...           ...\n",
       "14694  https://t.co/KJUowqIpT2 \"Procedimentos s√£o mui...        Neutro\n",
       "14695  #Noticia #MPU: Est√° confirmado que o #edital s...        Neutro\n",
       "14696  Programa√ß√£o SIPAT 2018 https://t.co/tJEy1KERUx...        Neutro\n",
       "14697  #TheVoiceBrasil Esses jurados viram mais pela ...        Neutro\n",
       "14698  A onda da transforma√ß√£o s√≥ cresce. Dia 7 de ou...        Neutro\n",
       "\n",
       "[14699 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_classificada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processamento de dados\n",
    "Agora ser√° feita v√°rias tecnicas de processamento nos tweets e ser√° apresentado os resultados e como √© afetado.<br/>\n",
    "Os vetores de frequ√™ncia e tfidf ter√£o que ser criados de novo.<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processamento  da base de treino e teste\n",
    "Por cada t√©cnica que a base passar, o resultado vai ser armazenado para testes futuros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remo√ß√£o de URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_classificada['URL'] = _lower(base_classificada[\"Text\"].values)\n",
    "base_classificada['URL'] = _remove_url(base_classificada['URL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remo√ß√£o de Hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_classificada['Hashtags'] = _remove_hashtag(base_classificada['URL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_classificada['Mencoes'] = _remove_mencao(base_classificada['Hashtags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = _tokenize(base_classificada['Mencoes'])\n",
    "tokens = _padroniza_tokens(tokens, lista_abreviacoes)\n",
    "base_classificada['Abreviacoes'] = _destokeniza(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = _tokenize(base_classificada['Abreviacoes'])\n",
    "tokens = _replace_emoticons(tokens, emoticon_list)\n",
    "base_classificada['Emoticons'] = _destokeniza(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = _tokenize(base_classificada['Emoticons'])\n",
    "tokens = _remove_stopwords(tokens, stopwords_customizadas)\n",
    "base_classificada['Stopwords'] = _destokeniza(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Classificacao</th>\n",
       "      <th>URL</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Mencoes</th>\n",
       "      <th>Abreviacoes</th>\n",
       "      <th>Emoticons</th>\n",
       "      <th>Stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Trio √© detido ap√≥s assaltar pizzaria em Uberl√¢...</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>trio √© detido ap√≥s assaltar pizzaria em uberl√¢...</td>\n",
       "      <td>trio √© detido ap√≥s assaltar pizzaria em uberl√¢...</td>\n",
       "      <td>trio √© detido ap√≥s assaltar pizzaria em uberl√¢...</td>\n",
       "      <td>trio √© detido ap√≥s assaltar pizzaria em uberl√¢...</td>\n",
       "      <td>trio √© detido ap√≥s assaltar pizzaria em uberl√¢...</td>\n",
       "      <td>trio detido ap√≥s assaltar pizzaria uberl√¢ndia ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>@PMMG190 - 42¬∫ BPM: POLICIAIS MILITARES DE CUR...</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>@pmmg190 - 42¬∫ bpm: policiais militares de cur...</td>\n",
       "      <td>@pmmg190 - 42¬∫ bpm: policiais militares de cur...</td>\n",
       "      <td>- 42¬∫ bpm: policiais militares de curvelo pre...</td>\n",
       "      <td>- 42¬∫ bpm : policiais militares de curvelo pre...</td>\n",
       "      <td>- 42¬∫ bpm : policiais militares de curvelo pre...</td>\n",
       "      <td>42¬∫ bpm policiais militares curvelo prendem tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Pres√≠dio em Minas adota novo modelo e consegue...</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>pres√≠dio em minas adota novo modelo e consegue...</td>\n",
       "      <td>pres√≠dio em minas adota novo modelo e consegue...</td>\n",
       "      <td>pres√≠dio em minas adota novo modelo e consegue...</td>\n",
       "      <td>pres√≠dio em minas adota novo modelo e consegue...</td>\n",
       "      <td>pres√≠dio em minas adota novo modelo e consegue...</td>\n",
       "      <td>pres√≠dio minas adota novo modelo consegue recu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Um jovem √© preso, um menor apreendido por tr√°f...</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>um jovem √© preso, um menor apreendido por tr√°f...</td>\n",
       "      <td>um jovem √© preso, um menor apreendido por tr√°f...</td>\n",
       "      <td>um jovem √© preso, um menor apreendido por tr√°f...</td>\n",
       "      <td>um jovem √© preso , um menor apreendido por tr√°...</td>\n",
       "      <td>um jovem √© preso , um menor apreendido por tr√°...</td>\n",
       "      <td>jovem preso menor apreendido tr√°fico drogas zo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Trio √© preso suspeito de roubo, tr√°fico e abus...</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>trio √© preso suspeito de roubo, tr√°fico e abus...</td>\n",
       "      <td>trio √© preso suspeito de roubo, tr√°fico e abus...</td>\n",
       "      <td>trio √© preso suspeito de roubo, tr√°fico e abus...</td>\n",
       "      <td>trio √© preso suspeito de roubo , tr√°fico e abu...</td>\n",
       "      <td>trio √© preso suspeito de roubo , tr√°fico e abu...</td>\n",
       "      <td>trio preso suspeito roubo tr√°fico abuso sexual...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Classificacao  \\\n",
       "0  Trio √© detido ap√≥s assaltar pizzaria em Uberl√¢...      Positivo   \n",
       "1  @PMMG190 - 42¬∫ BPM: POLICIAIS MILITARES DE CUR...      Positivo   \n",
       "2  Pres√≠dio em Minas adota novo modelo e consegue...      Positivo   \n",
       "3  Um jovem √© preso, um menor apreendido por tr√°f...      Positivo   \n",
       "4  Trio √© preso suspeito de roubo, tr√°fico e abus...      Positivo   \n",
       "\n",
       "                                                 URL  \\\n",
       "0  trio √© detido ap√≥s assaltar pizzaria em uberl√¢...   \n",
       "1  @pmmg190 - 42¬∫ bpm: policiais militares de cur...   \n",
       "2  pres√≠dio em minas adota novo modelo e consegue...   \n",
       "3  um jovem √© preso, um menor apreendido por tr√°f...   \n",
       "4  trio √© preso suspeito de roubo, tr√°fico e abus...   \n",
       "\n",
       "                                            Hashtags  \\\n",
       "0  trio √© detido ap√≥s assaltar pizzaria em uberl√¢...   \n",
       "1  @pmmg190 - 42¬∫ bpm: policiais militares de cur...   \n",
       "2  pres√≠dio em minas adota novo modelo e consegue...   \n",
       "3  um jovem √© preso, um menor apreendido por tr√°f...   \n",
       "4  trio √© preso suspeito de roubo, tr√°fico e abus...   \n",
       "\n",
       "                                             Mencoes  \\\n",
       "0  trio √© detido ap√≥s assaltar pizzaria em uberl√¢...   \n",
       "1   - 42¬∫ bpm: policiais militares de curvelo pre...   \n",
       "2  pres√≠dio em minas adota novo modelo e consegue...   \n",
       "3  um jovem √© preso, um menor apreendido por tr√°f...   \n",
       "4  trio √© preso suspeito de roubo, tr√°fico e abus...   \n",
       "\n",
       "                                         Abreviacoes  \\\n",
       "0  trio √© detido ap√≥s assaltar pizzaria em uberl√¢...   \n",
       "1  - 42¬∫ bpm : policiais militares de curvelo pre...   \n",
       "2  pres√≠dio em minas adota novo modelo e consegue...   \n",
       "3  um jovem √© preso , um menor apreendido por tr√°...   \n",
       "4  trio √© preso suspeito de roubo , tr√°fico e abu...   \n",
       "\n",
       "                                           Emoticons  \\\n",
       "0  trio √© detido ap√≥s assaltar pizzaria em uberl√¢...   \n",
       "1  - 42¬∫ bpm : policiais militares de curvelo pre...   \n",
       "2  pres√≠dio em minas adota novo modelo e consegue...   \n",
       "3  um jovem √© preso , um menor apreendido por tr√°...   \n",
       "4  trio √© preso suspeito de roubo , tr√°fico e abu...   \n",
       "\n",
       "                                           Stopwords  \n",
       "0  trio detido ap√≥s assaltar pizzaria uberl√¢ndia ...  \n",
       "1  42¬∫ bpm policiais militares curvelo prendem tr...  \n",
       "2  pres√≠dio minas adota novo modelo consegue recu...  \n",
       "3  jovem preso menor apreendido tr√°fico drogas zo...  \n",
       "4  trio preso suspeito roubo tr√°fico abuso sexual...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_classificada.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processamento dos dados coletados\n",
    "Apenas ser√° armazenado o resultado final do pr√©-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_classificada.to_csv('dados\\\\resultados\\\\base_treino_teste_processada.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_coletados_janeiro = pd.read_csv(\"dados\\\\coletados\\\\janeiro.csv\")\n",
    "tweets_coletados_fevereiro = pd.read_csv(\"dados\\\\coletados\\\\fevereiro.csv\")\n",
    "tweets_coletados_marco = pd.read_csv(\"dados\\\\coletados\\\\marco.csv\")\n",
    "tweets_coletados_abril = pd.read_csv(\"dados\\\\coletados\\\\abril.csv\")\n",
    "tweets_coletados_maio = pd.read_csv(\"dados\\\\coletados\\\\maio.csv\")\n",
    "tweets_coletados_junho = pd.read_csv(\"dados\\\\coletados\\\\junho.csv\")\n",
    "tweets_coletados_julho = pd.read_csv(\"dados\\\\coletados\\\\julho.csv\")\n",
    "tweets_coletados_agosto = pd.read_csv(\"dados\\\\coletados\\\\agosto.csv\")\n",
    "tweets_coletados_setembro = pd.read_csv(\"dados\\\\coletados\\\\setembro.csv\")\n",
    "tweets_coletados_outubro = pd.read_csv(\"dados\\\\coletados\\\\outubro.csv\")\n",
    "tweets_coletados_novembro = pd.read_csv(\"dados\\\\coletados\\\\novembro.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_coletados_janeiro[\"mes\"] = \"Janeiro\"\n",
    "tweets_coletados_fevereiro[\"mes\"] = \"Fevereiro\"\n",
    "tweets_coletados_marco[\"mes\"] = \"Marco\"\n",
    "tweets_coletados_abril[\"mes\"] = \"Abril\"\n",
    "tweets_coletados_maio[\"mes\"] = \"Maio\"\n",
    "tweets_coletados_junho[\"mes\"] = \"Junho\"\n",
    "tweets_coletados_julho[\"mes\"] = \"Julho\"\n",
    "tweets_coletados_agosto[\"mes\"] = \"Agosto\"\n",
    "tweets_coletados_setembro[\"mes\"] = \"Setembro\"\n",
    "tweets_coletados_outubro[\"mes\"] = \"Outubro\"\n",
    "tweets_coletados_novembro[\"mes\"] = \"Novembro\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_coletados = pd.DataFrame()\n",
    "tweets_coletados = pd.concat([tweets_coletados_janeiro, tweets_coletados_fevereiro, tweets_coletados_marco,\n",
    "                              tweets_coletados_abril, tweets_coletados_maio, tweets_coletados_junho,\n",
    "                              tweets_coletados_julho, tweets_coletados_agosto, tweets_coletados_setembro,\n",
    "                              tweets_coletados_outubro, tweets_coletados_novembro], ignore_index=True, sort=False)\n",
    "\n",
    "tweets_coletados = tweets_coletados.drop(columns=[\"username\", \"to\",\"replies\", \"retweets\", \"favorites\", \"geo\", \"mentions\", \"hashtags\", \"id\", \"permalink\", \"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_coletados['Texto Processado'] = _processamento(tweets_coletados['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>mes</th>\n",
       "      <th>Texto Processado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-31 23:59:17</td>\n",
       "      <td>‚òùÔ∏èE jornalista sabich√£o apoiando reforma fasci...</td>\n",
       "      <td>Janeiro</td>\n",
       "      <td>emoticon_positivo Ô∏è jornalista sabich√£o apoian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-31 23:59:03</td>\n",
       "      <td>Isso √© s√≥ uma demostra√ß√£o do que virar quando ...</td>\n",
       "      <td>Janeiro</td>\n",
       "      <td>demostra√ß√£o virar chegar congresso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-31 23:57:31</td>\n",
       "      <td>Governo diz que espera aprovar reforma da Prev...</td>\n",
       "      <td>Janeiro</td>\n",
       "      <td>governo diz espera aprovar 1¬∫ semestre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-01-31 23:56:44</td>\n",
       "      <td>Joice, mudadando de assunto, √© verdade q o gov...</td>\n",
       "      <td>Janeiro</td>\n",
       "      <td>joice mudadando assunto verdade governo pedind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-01-31 23:56:20</td>\n",
       "      <td>meu pai foi muito bolsominion arrepedindo fala...</td>\n",
       "      <td>Janeiro</td>\n",
       "      <td>pai bolsominion arrepedindo falando discurso m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date                                               text  \\\n",
       "0  2019-01-31 23:59:17  ‚òùÔ∏èE jornalista sabich√£o apoiando reforma fasci...   \n",
       "1  2019-01-31 23:59:03  Isso √© s√≥ uma demostra√ß√£o do que virar quando ...   \n",
       "2  2019-01-31 23:57:31  Governo diz que espera aprovar reforma da Prev...   \n",
       "3  2019-01-31 23:56:44  Joice, mudadando de assunto, √© verdade q o gov...   \n",
       "4  2019-01-31 23:56:20  meu pai foi muito bolsominion arrepedindo fala...   \n",
       "\n",
       "       mes                                   Texto Processado  \n",
       "0  Janeiro  emoticon_positivo Ô∏è jornalista sabich√£o apoian...  \n",
       "1  Janeiro                 demostra√ß√£o virar chegar congresso  \n",
       "2  Janeiro             governo diz espera aprovar 1¬∫ semestre  \n",
       "3  Janeiro  joice mudadando assunto verdade governo pedind...  \n",
       "4  Janeiro  pai bolsominion arrepedindo falando discurso m...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_coletados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_coletados.to_csv('dados\\\\resultados\\\\base_coletada_processada.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
